{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics as s\n",
    "\n",
    "# Own functions\n",
    "from data_preparation import preprocessing_functions_for_final_runs as preproc_final\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data_train = pd.read_csv('Data/Friends_data/Final_QA_datasets/qa_data_train.csv', sep='\\t', index_col=0)\n",
    "qa_data_tune = pd.read_csv('Data/Friends_data/Final_QA_datasets/qa_data_tune.csv', sep='\\t', index_col=0)\n",
    "qa_data_dev = pd.read_csv('Data/Friends_data/Final_QA_datasets/qa_data_dev.csv', sep='\\t', index_col=0)\n",
    "qa_data_test = pd.read_csv('Data/Friends_data/Final_QA_datasets/qa_data_test.csv', sep='\\t', index_col=0)\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev, Y_dev_original, X_test, Y_test, vocab, vocab_size, maxlen, tokenizer, number_of_labels = preproc_final.preprocessing(qa_data_train, qa_data_tune, qa_data_dev, qa_data_test, exclude=[5,6], multi_input=False, input_def='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and F1-score for DEV and TEST sets - average of 3 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = \"./predictions/CNN_bert/bert_loaded_dev1.npz\"\n",
    "dev2 = \"./predictions/CNN_bert/bert_loaded_dev2.npz\"\n",
    "dev3 = \"./predictions/CNN_bert/bert_loaded_dev3.npz\"\n",
    "\n",
    "test1 = \"./predictions/CNN_bert/bert_loaded_test1.npz\"\n",
    "test2 = \"./predictions/CNN_bert/bert_loaded_test2.npz\"\n",
    "test3 = \"./predictions/CNN_bert/bert_loaded_test3.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dev_1 = np.load(dev1)['arr_0']\n",
    "predictions_dev_2 = np.load(dev2)['arr_0']\n",
    "predictions_dev_3 = np.load(dev3)['arr_0']\n",
    "\n",
    "predictions_test_1 = np.load(test1)['arr_0']\n",
    "predictions_test_2 = np.load(test2)['arr_0']\n",
    "predictions_test_3 = np.load(test3)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dev1 = accuracy_score(Y_dev_original, predictions_dev_1)\n",
    "acc_dev2 = accuracy_score(Y_dev_original, predictions_dev_2)\n",
    "acc_dev3 = accuracy_score(Y_dev_original, predictions_dev_3)\n",
    "\n",
    "acc_test1 = accuracy_score(Y_test, predictions_test_1)\n",
    "acc_test2 = accuracy_score(Y_test, predictions_test_2)\n",
    "acc_test3 = accuracy_score(Y_test, predictions_test_3)\n",
    "\n",
    "fsc_dev1 = f1_score(Y_dev_original, predictions_dev_1, average='macro')\n",
    "fsc_dev2 = f1_score(Y_dev_original, predictions_dev_2, average='macro')\n",
    "fsc_dev3 = f1_score(Y_dev_original, predictions_dev_3, average='macro')\n",
    "\n",
    "fsc_test1 = f1_score(Y_test, predictions_test_1, average='macro')\n",
    "fsc_test2 = f1_score(Y_test, predictions_test_2, average='macro')\n",
    "fsc_test3 = f1_score(Y_test, predictions_test_3, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_dev_acc = (acc_dev1 + acc_dev2 + acc_dev3) / 3\n",
    "average_test_acc = (acc_test1 + acc_test2 + acc_test3) / 3\n",
    "\n",
    "average_dev_fsc = (fsc_dev1 + fsc_dev2 + fsc_dev3) / 3\n",
    "average_test_fsc = (fsc_test1 + fsc_test2 + fsc_test3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV: \n",
      "Average accuracy: 64.081 with standard deviation: 0.446\n",
      "Average f1-score: 49.161 with standard deviation: 3.956\n",
      "\n",
      "TEST: \n",
      "Average accuracy: 61.327 with standard deviation: 0.487\n",
      "Average f1-score: 45.647 with standard deviation: 3.164\n"
     ]
    }
   ],
   "source": [
    "print(\"DEV: \\nAverage accuracy: {} with standard deviation: {}\".format(np.round(average_dev_acc*100,3), np.round(s.stdev([acc_dev1,acc_dev2,acc_dev3])*100,3)))\n",
    "print(\"Average f1-score: {} with standard deviation: {}\".format(np.round(average_dev_fsc*100,3), np.round(s.stdev([fsc_dev1,fsc_dev2,fsc_dev3])*100,3)))\n",
    "print()\n",
    "print(\"TEST: \\nAverage accuracy: {} with standard deviation: {}\".format(np.round(average_test_acc*100,3), np.round(s.stdev([acc_test1,acc_test2,acc_test3])*100,3)))\n",
    "print(\"Average f1-score: {} with standard deviation: {}\".format(np.round(average_test_fsc*100,3), np.round(s.stdev([fsc_test1,fsc_test2,fsc_test3])*100,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-wise F1-score for DEV set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73       291\n",
      "           1       0.61      0.44      0.52       153\n",
      "           2       0.60      0.21      0.32        14\n",
      "           3       0.55      0.61      0.58       135\n",
      "\n",
      "    accuracy                           0.64       593\n",
      "   macro avg       0.61      0.51      0.53       593\n",
      "weighted avg       0.63      0.64      0.63       593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74       291\n",
      "           1       0.64      0.42      0.51       153\n",
      "           2       0.25      0.07      0.11        14\n",
      "           3       0.58      0.58      0.58       135\n",
      "\n",
      "    accuracy                           0.65       593\n",
      "   macro avg       0.54      0.47      0.48       593\n",
      "weighted avg       0.64      0.65      0.63       593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       291\n",
      "           1       0.55      0.52      0.54       153\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.66      0.48      0.56       135\n",
      "\n",
      "    accuracy                           0.64       593\n",
      "   macro avg       0.47      0.45      0.46       593\n",
      "weighted avg       0.62      0.64      0.62       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DEV:\")\n",
    "print(classification_report(Y_dev_original, predictions_dev_1))\n",
    "print(classification_report(Y_dev_original, predictions_dev_2))\n",
    "print(classification_report(Y_dev_original, predictions_dev_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_1 = f1_score(Y_dev_original,predictions_dev_1,average=None)\n",
    "f1_2 = f1_score(Y_dev_original,predictions_dev_2,average=None)\n",
    "f1_3 = f1_score(Y_dev_original,predictions_dev_3,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72727273 0.51515152 0.31578947 0.57839721]\n",
      "[0.74418605 0.50592885 0.11111111 0.57777778]\n",
      "[0.73125    0.53691275 0.         0.55555556]\n"
     ]
    }
   ],
   "source": [
    "print(f1_1)\n",
    "print(f1_2)\n",
    "print(f1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73423626 0.51933104 0.14230019 0.57057685]\n"
     ]
    }
   ],
   "source": [
    "print(np.average(np.asarray((f1_1,f1_2,f1_3)),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
